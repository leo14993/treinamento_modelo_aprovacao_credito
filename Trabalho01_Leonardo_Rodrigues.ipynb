{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as dependencias necessárias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tqdm import tqdm # verifica o progresso de uma tarefa\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instalar pip install pandas-profilling\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Dataframe e limpeza de dados\n",
    "\n",
    "\n",
    "#### Motivos de limpeza genericos:\n",
    "* estado_onde_nasceu - informacao desnecessaria \n",
    "* id_solicitante - informação com dados unicos\n",
    "* grau_instrucao - apenas possui valor 0\n",
    "* estado_onde_trabalha - muitos dados nulos\n",
    "* codigo_area_telefone_trabalho - informação desnecessaria\n",
    "* codigo_area_telefone_residencial - informação desnecessaria\n",
    "* possui_telefone_celular - apenas possui valor \"N\"\n",
    "* local_onde_trabalha - local_onde_reside igual a local_onde_trabalha\n",
    "\n",
    "\n",
    "#### Os dados abaixo possuem muitos valores nulos:\n",
    "\n",
    "* grau_instrucao_companheiro - 12860 dados nulos (64.3%) \n",
    "* profissao_companheiro - 11514 dados nulos (57.6%)\n",
    "\n",
    "#### Teste com alguns dados:\n",
    "Ao remover um desses valores, no modelo RandomForestClassifier, foi observado o seguinte comportamento:\n",
    "* possui_email - essa informação reduz a acuracia do modelo (~ 0.15%)\n",
    "* local_onde_reside - essa informação reduz a acuracia do modelo (~0.29%)\n",
    "Porém ao utilizar esses dois dados juntos, o modelo apresentou uma melhora de acuracia superior a acuracia observado ao remover os dois dados. Então foi decidido manter esses dois atributos.\n",
    "\n",
    "Ao expandir o atributo `estado_onde_reside` em 27 colunas com valores binarios (0/1) foi observado redução na acuracia do modelo, então esse atributo também será removido, além disso, visualmente os atributos `local_onde_reside` e `estado_onde_reside` possuem uma certa correlação, e como `local_onde_reside` e `possui_email` possuem sinergia, é preferivel manter `local_onde_reside` ao invés de `estado_onde_reside` .\n",
    "\n",
    "Apos a limpeza sobraram 15.568 de 20.000 ( ~22.16% de remoção)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('conjunto_de_treinamento.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando arquivo de analise do dataset\n",
    "\n",
    "Nesta etapa é gerado um arquivo html onde é feita uma varredura nos dados, retornando quais são as possíveis correlações entre as colunas, numero de amostras nulas, repetição de dados, tipo dos dados, análises estatisticas como os quartis, desvio padrão, variância. No final do arquivo há uma matriz de correlação dos dados.\n",
    "\n",
    "Antes de gerar esse arquivo com o diagnóstico dos dados, foi decidido remover algumas colunas que foram consideradas insignificantes, ou por contribuir negativamente na acurácia do modelo.\n",
    "\n",
    "a biblioteca \"pandas_profiling\" é instalada através do comando `pip install pandas-profiling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(df)\n",
    "prof.to_file(output_file='analise_inicial_dados.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluindo colunas desnecessárias após analizar o dataframe com o profile report, e após testar de outras formas descritas anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['estado_onde_nasceu',  #informacao desnecessaria \n",
    "                    'id_solicitante', \n",
    "                    'grau_instrucao',  # apenas possui valor 0 \n",
    "                    'estado_onde_trabalha',\n",
    "                    'codigo_area_telefone_trabalho',\n",
    "                    'codigo_area_telefone_residencial',\n",
    "                    'possui_telefone_celular',  # apenas possui valor \"N\" \n",
    "                    'local_onde_trabalha',  #local_onde_reside igual a local_onde_trabalha\n",
    "                    'estado_onde_reside',                    \n",
    "                    'grau_instrucao_companheiro',\n",
    "                    'profissao_companheiro',\n",
    "                    \n",
    "                   ],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando dataframe após a exclusao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(df)\n",
    "prof.to_file(output_file='analise_apos_limpeza.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.read_csv('conjunto_de_teste.csv')\n",
    "\n",
    "df_teste = df_teste.drop(['estado_onde_nasceu',  #informacao desnecessaria \n",
    "#                     'id_solicitante', \n",
    "                    'grau_instrucao',  # apenas possui valor 0 \n",
    "                    'estado_onde_trabalha',\n",
    "                    'codigo_area_telefone_trabalho',\n",
    "                    'codigo_area_telefone_residencial',\n",
    "                    'possui_telefone_celular',  # apenas possui valor \"N\" \n",
    "                    'local_onde_trabalha',  #local_onde_reside igual a local_onde_trabalha\n",
    "                    'estado_onde_reside',\n",
    "                    \n",
    "#                     'possui_email',                     \n",
    "                    'grau_instrucao_companheiro',\n",
    "                    'profissao_companheiro',\n",
    "#                     'local_onde_reside',\n",
    "#                     'forma_envio_solicitacao',\n",
    "#                     'sexo'\n",
    "                    \n",
    "                   ],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo variaveis categoricas e binarizando dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No conjunto de treino foi decidido excluir os dados que apresentam nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas = [\n",
    "    x for x in df.columns if df[x].dtype == 'object' or x == 'area_code'\n",
    "    ]\n",
    "\n",
    "df = pd.get_dummies(df,columns=[\n",
    "                                'forma_envio_solicitacao',\n",
    "                                'sexo'\n",
    "                               ])\n",
    "\n",
    "binarizador = LabelBinarizer()\n",
    "for v in ['possui_telefone_residencial',\n",
    "        'vinculo_formal_com_empresa','possui_telefone_trabalho']:\n",
    "    df[v] = binarizador.fit_transform(df[v])\n",
    "    \n",
    "# df = df.dropna()\n",
    "\n",
    "# df['profissao'] = df['profissao'].fillna(df['profissao'].mode()[0])\n",
    "df['profissao'] = df['profissao'].fillna(df['profissao'].mode()[0])\n",
    "df['ocupacao'] = df['ocupacao'].fillna(df['ocupacao'].mode()[0])\n",
    "df['meses_na_residencia'] = df['meses_na_residencia'].fillna(df['meses_na_residencia'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No conjunto de teste os valores nulos foram substituidos pelos valores de moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_categoricas = [\n",
    "    x for x in df_teste.columns if df_teste[x].dtype == 'object' or x == 'area_code'\n",
    "    ]\n",
    "\n",
    "df_teste = pd.get_dummies(df_teste,columns=[\n",
    "                                'forma_envio_solicitacao',\n",
    "                                'sexo'\n",
    "                               ])\n",
    "\n",
    "binarizador = LabelBinarizer()\n",
    "for v in ['possui_telefone_residencial',\n",
    "        'vinculo_formal_com_empresa','possui_telefone_trabalho']:\n",
    "    df_teste[v] = binarizador.fit_transform(df_teste[v])\n",
    "    \n",
    "\n",
    "df_teste['profissao'] = df_teste['profissao'].fillna(df_teste['profissao'].mode()[0])\n",
    "df_teste['ocupacao'] = df_teste['ocupacao'].fillna(df_teste['ocupacao'].mode()[0])\n",
    "df_teste['meses_na_residencia'] = df_teste['meses_na_residencia'].fillna(df_teste['meses_na_residencia'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_selecionados = [\n",
    "'sexo_ ',\n",
    "'sexo_M',\n",
    "'sexo_F',\n",
    "'sexo_N',\n",
    "'possui_email',\n",
    "'local_onde_reside',\n",
    "'tipo_endereco',\n",
    "'idade',\n",
    "'estado_civil',\n",
    "'qtde_dependentes',\n",
    "'dia_vencimento',  \n",
    "'possui_telefone_residencial',   \n",
    "'meses_na_residencia',\n",
    "'renda_mensal_regular',\n",
    "'renda_extra',\n",
    "'possui_cartao_visa',\n",
    "'possui_cartao_mastercard',  \n",
    "'possui_outros_cartoes',\n",
    "'qtde_contas_bancarias',\n",
    "'qtde_contas_bancarias_especiais',\n",
    "'valor_patrimonio_pessoal',\n",
    "'possui_carro',\n",
    "'vinculo_formal_com_empresa',  \n",
    "'meses_no_trabalho',\n",
    "'profissao',\n",
    "'ocupacao',\n",
    "'forma_envio_solicitacao_correio',\n",
    "'forma_envio_solicitacao_internet',\n",
    "'forma_envio_solicitacao_presencial',\n",
    "    \n",
    "'inadimplente'\n",
    "]\n",
    "\n",
    "dados_selecionados = df[atributos_selecionados]\n",
    "\n",
    "dados_embaralhados = dados_selecionados.sample(frac=1,random_state=12345)\n",
    "\n",
    "x = dados_embaralhados.loc[:,dados_embaralhados.columns!='inadimplente'].values\n",
    "y = dados_embaralhados.loc[:,dados_embaralhados.columns=='inadimplente'].values\n",
    "\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    x,\n",
    "    y.ravel(),\n",
    "    test_size=0.01,\n",
    "    shuffle=True,\n",
    "    random_state=777\n",
    "    )\n",
    "\n",
    "ajustador_de_escala = MinMaxScaler()\n",
    "ajustador_de_escala.fit(x_treino)\n",
    "\n",
    "x_treino = ajustador_de_escala.transform(x_treino)\n",
    "x_teste  = ajustador_de_escala.transform(x_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando e avaliando diferentes modelos\n",
    "\n",
    "Após treinar alguns modelos, foi decidido que RandomForest e GradientBoosting foram os que apresentaram melhores resultados.\n",
    "E baseado em algumas pesquisas:\n",
    "\n",
    "* https://www.datasciencecentral.com/profiles/blogs/decision-tree-vs-random-forest-vs-boosted-trees-explained\n",
    "        \n",
    "* https://www.datacamp.com/community/tutorials/random-forests-classifier-python?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=278443377095&utm_targetid=aud-392016246653:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=1001655&gclid=CjwKCAjwm7mEBhBsEiwA_of-TMa9e-x8s99xu1TOGVHuT24xXCHgq8znmeG7FCvVcqRE3k-emNXirRoC8OUQAvD_BwE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier\n",
    "\n",
    "criterion='entropy'\n",
    "\n",
    "scores:[0.59152216 0.58381503 0.58831085 0.59216442 0.58574181 0.58445729\n",
    " 0.59922929 0.59666024 0.57133676 0.58033419] acurácia média = 58.74 %\n",
    "\n",
    "criterion='gini'\n",
    "scores:[0.58702633 0.58124599 0.58702633 0.5973025  0.59344894 0.58124599\n",
    " 0.59666024 0.59152216 0.57455013 0.58226221] acurácia média = 58.72 %\n",
    " \n",
    "\n",
    "Após realizar alguns experimentos alterando o valor de  max_depth mantendo o mesmo random_state, foi notado que o valor da acuracia aumenta, porém quando max_depth é maior que 4 os valores começam a se comportar de forma aleatoria em torno do maximo observado em max_depth=4, assim foi decidido manter max_depth=4.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    max_depth=4, \n",
    "#                              random_state=0, \n",
    "                             criterion='entropy', \n",
    "#                              max_features='log2',\n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0)\n",
    "# clf.fit(x_treino, y_treino)\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x_treino,\n",
    "        y_treino.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "#     f\"numero de estimadore: {k}\",\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = []\n",
    "for k in tqdm(range(1,10,1)):\n",
    "#     print(f\"numero de estimadore: {k}\")\n",
    "    clf = RandomForestClassifier(max_depth=k, \n",
    "                                 random_state=0, \n",
    "                                 criterion='entropy', \n",
    "    #                              max_features='log2',\n",
    "                                 min_samples_split=2, \n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0)\n",
    "    # clf.fit(x_treino, y_treino)\n",
    "\n",
    "    q = 10\n",
    "    scores = cross_val_score(\n",
    "            clf,\n",
    "            x,\n",
    "            y.ravel(),\n",
    "            cv=q\n",
    "            )\n",
    "    acuracias.append(round(100*mean(scores),2))\n",
    "\n",
    "    print (\n",
    "    #         f'k = {k}',\n",
    "        f\"numero de estimadore: {k}\",\n",
    "            f'scores:{scores}',\n",
    "            f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "            )\n",
    "print(f\"acuracias: {acuracias}\")\n",
    "print(f\"media acuracias: {mean(acuracias)}\")\n",
    "\n",
    "\n",
    "    # print(clf.predict(x_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Variando o valor de max_depth\n",
    " \n",
    " 5%|████▎                                                                              | 1/19 [00:03<01:05,  3.63s/it]\n",
    "numero de estimadore: 1 scores:[0.56775851 0.57353886 0.55234425 0.57867694 0.57096981 0.55362877\n",
    " 0.57353886 0.55427103 0.55655527 0.57005141] acurácia média = 56.51 %\n",
    " 11%|████████▋                                                                          | 2/19 [00:07<01:08,  4.05s/it]\n",
    "numero de estimadore: 2 scores:[0.58509955 0.57353886 0.58317277 0.58317277 0.57418112 0.56390495\n",
    " 0.58509955 0.57418112 0.5655527  0.5655527 ] acurácia média = 57.53 %\n",
    " 16%|█████████████                                                                      | 3/19 [00:13<01:14,  4.65s/it]\n",
    "numero de estimadore: 3 scores:[0.58831085 0.5761079  0.57482338 0.58831085 0.56647399 0.58124599\n",
    " 0.58509955 0.58702633 0.56426735 0.57712082] acurácia média = 57.89 %\n",
    " 21%|█████████████████▍                                                                 | 4/19 [00:19<01:20,  5.35s/it]\n",
    "numero de estimadore: 4 scores:[0.58959538 0.58060373 0.57675016 0.59023764 0.58638407 0.57739242\n",
    " 0.59987155 0.59152216 0.57455013 0.58097686] acurácia média = 58.48 %\n",
    " 26%|█████████████████████▊                                                             | 5/19 [00:26<01:23,  5.99s/it]\n",
    "numero de estimadore: 5 scores:[0.58702633 0.58188825 0.58959538 0.58766859 0.58509955 0.5793192\n",
    " 0.59537572 0.59280668 0.57712082 0.58611825] acurácia média = 58.62 %\n",
    " 32%|██████████████████████████▏                                                        | 6/19 [00:34<01:27,  6.71s/it]\n",
    "numero de estimadore: 6 scores:[0.5940912  0.57996146 0.58831085 0.58831085 0.58317277 0.57096981\n",
    " 0.59858703 0.58959538 0.5751928  0.57840617] acurácia média = 58.47 %\n",
    " 37%|██████████████████████████████▌                                                    | 7/19 [00:44<01:31,  7.60s/it]\n",
    "numero de estimadore: 7 scores:[0.58831085 0.58895311 0.59023764 0.59023764 0.58831085 0.57675016\n",
    " 0.59023764 0.58702633 0.57583548 0.5777635 ] acurácia média = 58.54 %\n",
    " 42%|██████████████████████████████████▉                                                | 8/19 [00:55<01:34,  8.61s/it]\n",
    "numero de estimadore: 8 scores:[0.5908799  0.58766859 0.58831085 0.59216442 0.58445729 0.58253051\n",
    " 0.59794477 0.58895311 0.58161954 0.58804627] acurácia média = 58.83 %\n",
    " 47%|███████████████████████████████████████▎                                           | 9/19 [01:06<01:33,  9.37s/it]\n",
    "numero de estimadore: 9 scores:[0.58638407 0.58831085 0.58445729 0.5908799  0.5793192  0.58253051\n",
    " 0.5940912  0.59023764 0.57262211 0.57262211] acurácia média = 58.41 %\n",
    " 53%|███████████████████████████████████████████▏                                      | 10/19 [01:18<01:31, 10.21s/it]\n",
    "numero de estimadore: 10 scores:[0.5940912  0.59858703 0.58702633 0.59922929 0.57546564 0.58253051\n",
    " 0.59152216 0.60115607 0.56619537 0.57712082] acurácia média = 58.73 %\n",
    " 58%|███████████████████████████████████████████████▍                                  | 11/19 [01:30<01:26, 10.87s/it]\n",
    "numero de estimadore: 11 scores:[0.58574181 0.60372511 0.58574181 0.58959538 0.58638407 0.58124599\n",
    " 0.58574181 0.59601798 0.57712082 0.57583548] acurácia média = 58.67 %\n",
    " 63%|███████████████████████████████████████████████████▊                              | 12/19 [01:44<01:21, 11.63s/it]\n",
    "numero de estimadore: 12 scores:[0.58831085 0.60115607 0.57739242 0.59344894 0.58124599 0.57353886\n",
    " 0.57546564 0.58060373 0.57455013 0.59318766] acurácia média = 58.39 %\n",
    " 68%|████████████████████████████████████████████████████████                          | 13/19 [01:58<01:14, 12.38s/it]\n",
    "numero de estimadore: 13 scores:[0.58831085 0.59666024 0.57739242 0.60308285 0.57675016 0.57032755\n",
    " 0.57096981 0.59344894 0.57583548 0.5777635 ] acurácia média = 58.31 %\n",
    " 74%|████████████████████████████████████████████████████████████▍                     | 14/19 [02:13<01:05, 13.14s/it]\n",
    "numero de estimadore: 14 scores:[0.58381503 0.58831085 0.56518947 0.59922929 0.56583173 0.58188825\n",
    " 0.56840077 0.58702633 0.5655527  0.57712082] acurácia média = 57.82 %\n",
    " 79%|████████████████████████████████████████████████████████████████▋                 | 15/19 [02:30<00:57, 14.29s/it]\n",
    "numero de estimadore: 15 scores:[0.57739242 0.60308285 0.56647399 0.58766859 0.57225434 0.58060373\n",
    " 0.56390495 0.5793192  0.56041131 0.57647815] acurácia média = 57.68 %\n",
    " 84%|█████████████████████████████████████████████████████████████████████             | 16/19 [02:48<00:46, 15.60s/it]\n",
    "numero de estimadore: 16 scores:[0.57225434 0.60051381 0.55876686 0.5793192  0.57482338 0.57546564\n",
    " 0.5728966  0.57096981 0.56876607 0.56619537] acurácia média = 57.4 %\n",
    " 89%|█████████████████████████████████████████████████████████████████████████▎        | 17/19 [03:07<00:33, 16.71s/it]\n",
    "numero de estimadore: 17 scores:[0.57096981 0.58509955 0.56454721 0.5728966  0.56518947 0.5728966\n",
    " 0.57867694 0.59023764 0.5655527  0.57197943] acurácia média = 57.38 %\n",
    " 95%|█████████████████████████████████████████████████████████████████████████████▋    | 18/19 [03:25<00:16, 16.99s/it]\n",
    "numero de estimadore: 18 scores:[0.58124599 0.59023764 0.55362877 0.58831085 0.56711625 0.56390495\n",
    " 0.56518947 0.57096981 0.56426735 0.56683805] acurácia média = 57.12 %\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [03:43<00:00, 11.78s/it]\n",
    "numero de estimadore: 19 scores:[0.56775851 0.59152216 0.55619782 0.57096981 0.56775851 0.56326268\n",
    " 0.56711625 0.57675016 0.57069409 0.57262211] acurácia média = 57.05 %\n",
    " \n",
    " \n",
    " valor de max_depth constante e igual a 5, observando a aleatoriedade dos dados:\n",
    " \n",
    "  11%|█████████▎                                                                          | 1/9 [00:07<00:56,  7.06s/it]\n",
    "numero de estimadore: 1 scores:[0.59601798 0.58253051 0.58638407 0.58959538 0.58766859 0.5793192\n",
    " 0.59473346 0.58831085 0.57647815 0.58419023] acurácia média = 58.65 %\n",
    " 22%|██████████████████▋                                                                 | 2/9 [00:14<00:49,  7.06s/it]\n",
    "numero de estimadore: 2 scores:[0.58702633 0.58445729 0.58188825 0.59601798 0.58959538 0.58317277\n",
    " 0.59601798 0.58445729 0.57197943 0.57969152] acurácia média = 58.54 %\n",
    " 33%|████████████████████████████                                                        | 3/9 [00:20<00:41,  6.96s/it]\n",
    "numero de estimadore: 3 scores:[0.58831085 0.58381503 0.58574181 0.58638407 0.58317277 0.57739242\n",
    " 0.59152216 0.58317277 0.57390746 0.58161954] acurácia média = 58.35 %\n",
    " 44%|█████████████████████████████████████▎                                              | 4/9 [00:27<00:34,  6.92s/it]\n",
    "numero de estimadore: 4 scores:[0.59473346 0.58060373 0.58831085 0.60115607 0.59023764 0.57803468\n",
    " 0.60436737 0.58895311 0.5751928  0.58997429] acurácia média = 58.92 %\n",
    " 56%|██████████████████████████████████████████████▋                                     | 5/9 [00:34<00:27,  6.92s/it]\n",
    "numero de estimadore: 5 scores:[0.5973025  0.58959538 0.58188825 0.58702633 0.58702633 0.58381503\n",
    " 0.59216442 0.59601798 0.57647815 0.58868895] acurácia média = 58.8 %\n",
    " 67%|████████████████████████████████████████████████████████                            | 6/9 [00:41<00:20,  6.89s/it]\n",
    "numero de estimadore: 6 scores:[0.59280668 0.58574181 0.58188825 0.59023764 0.58124599 0.58381503\n",
    " 0.58959538 0.59601798 0.57583548 0.57840617] acurácia média = 58.56 %\n",
    " 78%|█████████████████████████████████████████████████████████████████▎                  | 7/9 [00:48<00:13,  6.86s/it]\n",
    "numero de estimadore: 7 scores:[0.59216442 0.58638407 0.58895311 0.58574181 0.58702633 0.58253051\n",
    " 0.59344894 0.59023764 0.58226221 0.5874036 ] acurácia média = 58.76 %\n",
    " 89%|██████████████████████████████████████████████████████████████████████████▋         | 8/9 [00:55<00:06,  6.86s/it]\n",
    "numero de estimadore: 8 scores:[0.59280668 0.58188825 0.59216442 0.59280668 0.58895311 0.58253051\n",
    " 0.5973025  0.58574181 0.57647815 0.58161954] acurácia média = 58.72 %\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [01:02<00:00,  6.92s/it]\n",
    "numero de estimadore: 9 scores:[0.58766859 0.57996146 0.58381503 0.5908799  0.58574181 0.57418112\n",
    " 0.59344894 0.58959538 0.57840617 0.58161954] acurácia média = 58.45 %\n",
    "acuracias: [58.65, 58.54, 58.35, 58.92, 58.8, 58.56, 58.76, 58.72, 58.45]\n",
    "media acuracias: 58.638888888888886\n",
    "\n",
    "\n",
    "Em 10 experimentos observou-se que para um valor de max_depth=5 os valores de acuracia apresentaram uma media de 58.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos utilizados\n",
    "\n",
    "scores:[0.60950546 0.59152216 0.59794477 0.60436737 0.58445729 0.58702633\n",
    " 0.60051381 0.59280668 0.58161954 0.58868895]   \n",
    " acurácia média = 59.38 %\n",
    "\n",
    "atributos_selecionados=[\n",
    "'sexo_ ',  \n",
    "'sexo_M',  \n",
    "'sexo_F',  \n",
    "'sexo_N',  \n",
    "'possui_email',  \n",
    "'local_onde_reside',  \n",
    "'tipo_endereco',  \n",
    "'idade',  \n",
    "'estado_civil',  \n",
    "'qtde_dependentes',  \n",
    "'dia_vencimento',  \n",
    "'possui_telefone_residencial',   \n",
    "'meses_na_residencia',  \n",
    "'renda_mensal_regular',  \n",
    "'renda_extra',  \n",
    "'possui_cartao_visa',  \n",
    "'possui_cartao_mastercard',  \n",
    "'possui_outros_cartoes',  \n",
    "'qtde_contas_bancarias',  \n",
    "'qtde_contas_bancarias_especiais',  \n",
    "'valor_patrimonio_pessoal',  \n",
    "'possui_carro',  \n",
    "'vinculo_formal_com_empresa',  \n",
    "'meses_no_trabalho',  \n",
    "'profissao',  \n",
    "'ocupacao',  \n",
    "'forma_envio_solicitacao_correio',  \n",
    "'forma_envio_solicitacao_internet',  \n",
    "'forma_envio_solicitacao_presencial',  \n",
    "'inadimplente'\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando acurácia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "#     loss='exponential',\n",
    "#     n_estimators=245, \n",
    "    learning_rate=1.0,\n",
    "     max_depth=1, \n",
    "#     random_state=0,\n",
    "# max_leaf_nodes=10\n",
    ")\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf.fit(x_treino,y_treino.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando colunas do conjunto de teste para inserir no modelo criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_selecionados = [\n",
    "'sexo_ ',\n",
    "'sexo_M',\n",
    "'sexo_F',\n",
    "'sexo_N',\n",
    "'possui_email',\n",
    "'local_onde_reside',\n",
    "'tipo_endereco',\n",
    "'idade',\n",
    "'estado_civil',\n",
    "'qtde_dependentes',\n",
    "'dia_vencimento',  \n",
    "'possui_telefone_residencial',   \n",
    "'meses_na_residencia',\n",
    "'renda_mensal_regular',\n",
    "'renda_extra',\n",
    "'possui_cartao_visa',\n",
    "'possui_cartao_mastercard',  \n",
    "'possui_outros_cartoes',\n",
    "'qtde_contas_bancarias',\n",
    "'qtde_contas_bancarias_especiais',\n",
    "'valor_patrimonio_pessoal',\n",
    "'possui_carro',\n",
    "'vinculo_formal_com_empresa',  \n",
    "'meses_no_trabalho',\n",
    "'profissao',\n",
    "'ocupacao',\n",
    "'forma_envio_solicitacao_correio',\n",
    "'forma_envio_solicitacao_internet',\n",
    "'forma_envio_solicitacao_presencial',\n",
    "]\n",
    "\n",
    "testando_modelo = df_teste[atributos_selecionados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo a previsão do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = clf.predict(testando_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizando estrutura do modelo e convertendo para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_resultado = {'id_solicitante': df_teste['id_solicitante'], 'inadimplente': resultado.tolist()}\n",
    "df_resultado = pd.DataFrame(data=dict_resultado)\n",
    "df_resultado.to_csv (r'previsao_aprovacao_credito_ramdom_entropy.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(testando_modelo)\n",
    "prof.to_file(output_file='output_novo_teste.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_teste['id_solicitante'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ids = \n",
    "\n",
    "print(len(resultado.tolist()))\n",
    "print(len(df_teste['id_solicitante']))\n",
    "\n",
    "d = {'id_solicitante': df_teste['id_solicitante'], 'inadimplente': resultado.tolist()}\n",
    "df_res = pd.DataFrame(data=d)\n",
    "print(df_res)\n",
    "\n",
    "print(type(ids))\n",
    "print(type(resultado))\n",
    "\n",
    "# ids['inadimplente'] = resultado.tolist()\n",
    "# m = ids.insert(0,\"inadimplente\",resultado )\n",
    "# print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_res.to_csv (r'C:\\Users\\Ron\\Desktop\\export_dataframe.csv', index = False, header=True)\n",
    "df_res.to_csv (r'export_dataframe_3.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                             n_informative=2, n_redundant=0,\n",
    "#                             random_state=0, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, \n",
    "                             random_state=0, \n",
    "                             criterion='entropy', \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0)\n",
    "# clf.fit(x_treino, y_treino)\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )\n",
    "\n",
    "\n",
    "# print(clf.predict(x_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste dos dados de teste\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(x,y.ravel())\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Obter as respostas do classificador no mesmo conjunto onde foi treinado\n",
    "#-------------------------------------------------------------------------------\n",
    "dados = pd.read_csv('conjunto_de_teste.csv')\n",
    "\n",
    "\n",
    "# y_resposta_treino = classificador.predict(x_treino)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.std([0.5285806,  0.55234425, 0.50867052,0.49325626,0.54206808, 0.52280026,\n",
    " 0.50545922,0.55105973,0.54562982,0.56169666])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, \n",
    "                             random_state=0, \n",
    "                             criterion='entropy', \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0)\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# for k in range(39,50,2):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier( max_iter=1000)\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(200,301,20):\n",
    "    \n",
    "    print(f\" valor de k:{k}\")\n",
    "    \n",
    "    clf = MLPClassifier( max_iter=k)\n",
    "    q = 10\n",
    "    scores = cross_val_score(\n",
    "            clf,\n",
    "            x,\n",
    "            y.ravel(),\n",
    "            cv=q\n",
    "            )\n",
    "\n",
    "    print (\n",
    "    #         f'k = {k}',\n",
    "            f'scores:{scores}',\n",
    "            f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "# X_r2 = lda.fit(x, y).transform(x)\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf = LinearDiscriminantAnalysis(solver='lsqr', )\n",
    "\n",
    "# X_r2 = lda.fit(x, y).transform(x)\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "#     loss='exponential',\n",
    "    n_estimators=245, \n",
    "    learning_rate=1.0,\n",
    "     max_depth=1, \n",
    "#     random_state=0,\n",
    "# max_leaf_nodes=10\n",
    ")\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(range(245,256,1)):\n",
    "    print(f\"numero de estimadore: {k}\")\n",
    "    \n",
    "    clf = GradientBoostingClassifier(\n",
    "    #     loss='exponential',\n",
    "        n_estimators=k, \n",
    "        learning_rate=1.0,\n",
    "         max_depth=1, \n",
    "    #     random_state=0,\n",
    "    # max_leaf_nodes=10\n",
    "    )\n",
    "\n",
    "    q = 10\n",
    "    scores = cross_val_score(\n",
    "            clf,\n",
    "            x,\n",
    "            y.ravel(),\n",
    "            cv=q\n",
    "            )\n",
    "\n",
    "    print (\n",
    "    #         f'k = {k}',\n",
    "            f'scores:{scores}',\n",
    "            f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in tqdm(range(100,1000,50)):\n",
    "    print(f\"numero de estimadore: {k}\")\n",
    "    clf = GradientBoostingClassifier(\n",
    "    #     loss='exponential',\n",
    "        n_estimators=k, \n",
    "        learning_rate=1.0,\n",
    "         max_depth=1, \n",
    "    #     random_state=0,\n",
    "    # max_leaf_nodes=10\n",
    "    )\n",
    "\n",
    "    q = 10\n",
    "    scores = cross_val_score(\n",
    "            clf,\n",
    "            x,\n",
    "            y.ravel(),\n",
    "            cv=q\n",
    "            )\n",
    "\n",
    "    print (\n",
    "    #         f'k = {k}',\n",
    "            f'scores:{scores}',\n",
    "            f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com GradientBoostingClassifier\n",
    "\n",
    "\n",
    "De acordo com os resultados abaixo, foi observado que o tempo de execução de treinamento é proporcional ao `n_estimators`, por isso o ideal é manter esse valor o menor possível, o valor com melhor resultado foi de `n_estimators=250`\n",
    "Acompanhamento dos resultados baseados na alteração do parâmetro `n_estimators`\n",
    "\n",
    "Após decidir o n_estimators=250 foi feito uma verredura num intervalo mais estreito para validar o valor escolhido, e foi notado que em n_estimators=245 há um ganho de acuracia media.\n",
    "\n",
    "numero de estimadore: 245  \n",
    "scores:[0.61014772 0.59344894 0.58766859 0.60950546 0.58060373 0.59344894\n",
    " 0.59666024 0.60051381 0.57969152 0.58419023] \n",
    "acurácia média = 59.36%\n",
    " \n",
    "numero de estimadore: 246\n",
    "scores:[0.61078998 0.59537572 0.58381503 0.61014772 0.58188825 0.5908799\n",
    " 0.59601798 0.60179833 0.57840617 0.58290488] acurácia média = 59.32 %\n",
    "numero de estimadore: 247\n",
    " 27%|██████████████████████▋                                                            | 3/11 [00:49-02:11, 16.39s/it]\n",
    "scores:[0.61078998 0.59601798 0.58702633 0.61014772 0.58188825 0.59023764\n",
    " 0.59344894 0.60115607 0.57969152 0.5848329 ] acurácia média = 59.35 %\n",
    "numero de estimadore: 248\n",
    " 36%|██████████████████████████████▏                                                    | 4/11 [01:05-01:54, 16.43s/it]\n",
    "scores:[0.61078998 0.59473346 0.58574181 0.60950546 0.58124599 0.59280668\n",
    " 0.59601798 0.60308285 0.57904884 0.58290488] acurácia média = 59.36 %\n",
    "numero de estimadore: 249\n",
    " 45%|█████████████████████████████████████▋                                             | 5/11 [01:22-01:38, 16.47s/it]\n",
    "scores:[0.61078998 0.59473346 0.58702633 0.60950546 0.58188825 0.58895311\n",
    " 0.59537572 0.59987155 0.57969152 0.5848329 ] acurácia média = 59.33 %\n",
    "numero de estimadore: 250\n",
    " 55%|█████████████████████████████████████████████▎                                     | 6/11 [01:38-01:22, 16.55s/it]\n",
    "scores:[0.61078998 0.5940912  0.58574181 0.6088632  0.57996146 0.5940912\n",
    " 0.59794477 0.59987155 0.57969152 0.58290488] acurácia média = 59.34 %\n",
    "numero de estimadore: 251\n",
    " 64%|████████████████████████████████████████████████████▊                              | 7/11 [01:55-01:06, 16.69s/it]\n",
    "scores:[0.61078998 0.59537572 0.58574181 0.60950546 0.58124599 0.58831085\n",
    " 0.59537572 0.60051381 0.58097686 0.58547558] acurácia média = 59.33 %\n",
    "numero de estimadore: 252\n",
    " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [02:12-00:49, 16.67s/it]\n",
    "scores:[0.61078998 0.59601798 0.58766859 0.6088632  0.58124599 0.59344894\n",
    " 0.59601798 0.60051381 0.57840617 0.58226221] acurácia média = 59.35 %\n",
    "numero de estimadore: 253\n",
    " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [02:29-00:33, 16.65s/it]\n",
    "scores:[0.6088632  0.59666024 0.58574181 0.60500963 0.58124599 0.59023764\n",
    " 0.59280668 0.60179833 0.58033419 0.58354756] acurácia média = 59.26 %\n",
    "numero de estimadore: 254\n",
    " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [02:46-00:16, 16.77s/it]\n",
    "scores:[0.6120745  0.59537572 0.58702633 0.60565189 0.57996146 0.59152216\n",
    " 0.59473346 0.60115607 0.58226221 0.58161954] acurácia média = 59.31 %\n",
    "numero de estimadore: 255\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [03:03-00:00, 16.67s/it]\n",
    "scores:[0.6088632  0.59666024 0.59023764 0.60693642 0.58124599 0.58959538\n",
    " 0.59344894 0.60372511 0.57904884 0.58354756] acurácia média = 59.33 %\n",
    "\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    " \n",
    " \n",
    "entre 100 e 500 com passo de 50\n",
    "\n",
    " 0%|                                                                                            | 0/8 [00:00<?, ?it/s]\n",
    "numero de estimadore: 100\n",
    " 12%|██████████▌                                                                         | 1/8 [00:07<00:50,  7.16s/it]\n",
    "scores:[0.61335902 0.58702633 0.58060373 0.59987155 0.58317277 0.58959538\n",
    " 0.59987155 0.5940912  0.57197943 0.58161954] acurácia média = 59.01 %\n",
    "numero de estimadore: 150\n",
    " 25%|█████████████████████                                                               | 2/8 [00:18<00:57,  9.58s/it]\n",
    "scores:[0.61271676 0.58509955 0.57803468 0.60565189 0.58509955 0.58702633\n",
    " 0.59344894 0.5908799  0.57390746 0.59061697] acurácia média = 59.02 %\n",
    "numero de estimadore: 200\n",
    " 38%|███████████████████████████████▌                                                    | 3/8 [00:32<00:58, 11.77s/it]\n",
    "scores:[0.61335902 0.58831085 0.57996146 0.6088632  0.57675016 0.58959538\n",
    " 0.59344894 0.60051381 0.5777635  0.59061697] acurácia média = 59.19 %\n",
    "numero de estimadore: 250\n",
    " 50%|██████████████████████████████████████████                                          | 4/8 [00:50<00:56, 14.00s/it]\n",
    "scores:[0.61078998 0.5940912  0.58574181 0.6088632  0.57996146 0.5940912\n",
    " 0.59794477 0.59987155 0.57969152 0.58290488] acurácia média = 59.34 %\n",
    "numero de estimadore: 300\n",
    " 62%|████████████████████████████████████████████████████▌                               | 5/8 [01:10<00:49, 16.35s/it]\n",
    "scores:[0.61078998 0.59666024 0.58188825 0.60244059 0.58253051 0.58445729\n",
    " 0.59473346 0.60115607 0.58033419 0.58290488] acurácia média = 59.18 %\n",
    "numero de estimadore: 350\n",
    " 75%|███████████████████████████████████████████████████████████████                     | 6/8 [01:36<00:38, 19.38s/it]\n",
    "scores:[0.60693642 0.59794477 0.58574181 0.60693642 0.58445729 0.58188825\n",
    " 0.5973025  0.59537572 0.58097686 0.58354756] acurácia média = 59.21 %\n",
    "numero de estimadore: 400\n",
    " 88%|█████████████████████████████████████████████████████████████████████████▌          | 7/8 [02:03<00:22, 22.16s/it]\n",
    "scores:[0.60629416 0.59794477 0.58445729 0.60822094 0.57996146 0.58124599\n",
    " 0.59344894 0.59473346 0.58290488 0.58161954] acurácia média = 59.11 %\n",
    "numero de estimadore: 450\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [02:34<00:00, 19.27s/it]\n",
    "scores:[0.60693642 0.59987155 0.58188825 0.60950546 0.58188825 0.58702633\n",
    " 0.59280668 0.5973025  0.58097686 0.58676093] acurácia média = 59.25 %\n",
    "\n",
    "## Entre 500 e 100 com passo de 50\n",
    "\n",
    "0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
    "numero de estimadore: 500\n",
    " 10%|████████▎                                                                          | 1/10 [00:34<05:13, 34.86s/it]\n",
    "scores:[0.60308285 0.59987155 0.58702633 0.60950546 0.58317277 0.58188825\n",
    " 0.59344894 0.60179833 0.5848329  0.58547558] acurácia média = 59.3 %\n",
    "numero de estimadore: 550\n",
    " 20%|████████████████▌                                                                  | 2/10 [01:14<05:02, 37.79s/it]\n",
    "scores:[0.60565189 0.59987155 0.58574181 0.61785485 0.58060373 0.5793192\n",
    " 0.59023764 0.60051381 0.58161954 0.57969152] acurácia média = 59.21 %\n",
    "numero de estimadore: 600\n",
    " 30%|████████████████████████▉                                                          | 3/10 [01:56<04:36, 39.45s/it]\n",
    "scores:[0.60115607 0.60051381 0.58702633 0.62106615 0.57996146 0.58124599\n",
    " 0.58831085 0.60244059 0.57840617 0.58161954] acurácia média = 59.22 %\n",
    "numero de estimadore: 650\n",
    " 40%|█████████████████████████████████▏                                                 | 4/10 [02:49<04:29, 44.91s/it]\n",
    "scores:[0.60244059 0.59922929 0.58831085 0.61913937 0.58188825 0.57739242\n",
    " 0.58766859 0.60436737 0.5751928  0.5874036 ] acurácia média = 59.23 %\n",
    "numero de estimadore: 700\n",
    " 50%|█████████████████████████████████████████▌                                         | 5/10 [03:38<03:52, 46.56s/it]\n",
    "scores:[0.60179833 0.59987155 0.58702633 0.61785485 0.58638407 0.57996146\n",
    " 0.58702633 0.59987155 0.57390746 0.58676093] acurácia média = 59.2 %\n",
    "numero de estimadore: 750\n",
    " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [04:33<03:17, 49.34s/it]\n",
    "scores:[0.60051381 0.60179833 0.58766859 0.61785485 0.58895311 0.58124599\n",
    " 0.59152216 0.60051381 0.57583548 0.5874036 ] acurácia média = 59.33 %\n",
    "numero de estimadore: 800\n",
    " 70%|██████████████████████████████████████████████████████████                         | 7/10 [05:30<02:35, 51.82s/it]\n",
    "scores:[0.60051381 0.59922929 0.58831085 0.61592807 0.58574181 0.58060373\n",
    " 0.59152216 0.59794477 0.57455013 0.58676093] acurácia média = 59.21 %\n",
    "numero de estimadore: 850\n",
    " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [06:29<01:48, 54.17s/it]\n",
    "scores:[0.59922929 0.59987155 0.58381503 0.61528581 0.58766859 0.57867694\n",
    " 0.5908799  0.59794477 0.5751928  0.5848329 ] acurácia média = 59.13 %\n",
    "numero de estimadore: 900\n",
    " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [07:42<00:59, 59.83s/it]\n",
    "scores:[0.59794477 0.60244059 0.58638407 0.61849711 0.58509955 0.57803468\n",
    " 0.58766859 0.59794477 0.5777635  0.58290488] acurácia média = 59.15 %\n",
    "numero de estimadore: 950\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [08:50<00:00, 53.01s/it]\n",
    "scores:[0.59601798 0.60500963 0.58895311 0.61849711 0.58509955 0.5761079\n",
    " 0.58574181 0.5973025  0.57647815 0.57969152] acurácia média = 59.09 %\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "#     loss='exponential',\n",
    "    n_estimators=100, \n",
    "    learning_rate=1.0,\n",
    "     max_depth=1, \n",
    "    random_state=0,\n",
    "# max_leaf_nodes=10\n",
    ")\n",
    "\n",
    "q = 10\n",
    "scores = cross_val_score(\n",
    "        clf,\n",
    "        x,\n",
    "        y.ravel(),\n",
    "        cv=q\n",
    "        )\n",
    "\n",
    "print (\n",
    "#         f'k = {k}',\n",
    "        f'scores:{scores}',\n",
    "        f'acurácia média = {round(100*mean(scores),2)} %' \n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
